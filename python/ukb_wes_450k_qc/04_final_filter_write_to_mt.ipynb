{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "chrom = None", "metadata": {"tags": ["parameters"]}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import pyspark\nimport dxpy\nimport hail as hl\nimport pandas as pd\nfrom math import ceil\n\nWD='/opt/notebooks'", "metadata": {"trusted": true}, "execution_count": 1, "outputs": []}, {"cell_type": "code", "source": "my_database = dxpy.find_one_data_object(\n    name=\"my_database\", \n    project=dxpy.find_one_project()[\"id\"]\n)[\"id\"]\ndatabase_dir = f'dnax://{my_database}'\nsc = pyspark.SparkContext()\nspark = pyspark.sql.SparkSession(sc)\nhl.init(sc=sc, tmp_dir=f'{database_dir}/tmp/')", "metadata": {"trusted": true}, "execution_count": 2, "outputs": [{"name": "stderr", "text": "pip-installed Hail requires additional configuration options in Spark referring\n  to the path to the Hail Python module directory HAIL_DIR,\n  e.g. /path/to/python/site-packages/hail:\n    spark.jars=HAIL_DIR/hail-all-spark.jar\n    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\nSparkUI available at http://ip-10-60-128-217.eu-west-2.compute.internal:8081\nWelcome to\n     __  __     <>__\n    / /_/ /__  __/ /\n   / __  / _ `/ / /\n  /_/ /_/\\_,_/_/_/   version 0.2.78-b17627756568\nLOGGING: writing to /opt/notebooks/hail-20220928-0948-0.2.78-b17627756568.log\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "## S0. Define functions, load data", "metadata": {}}, {"cell_type": "code", "source": "def get_gnomad_vcf_path(chrom, blocks):\n    vcf_dir = 'file:///mnt/project/Bulk/Exome sequences_Alternative exome processing/Exome variant call files (gnomAD) (VCFs)'\n    if blocks != '*':\n        blocks = '{'+','.join(map(str, blocks))+'}'\n        \n    return f'{vcf_dir}/ukb24068_c{chrom}_b{blocks}_v1.vcf.gz'\n\n\ndef get_partitioned_chrom(chrom_w_suffix):\n    \"\"\"\n    chrom_w_suffix should be of the form \"{chr}-?of?\", e.g. \"8-1of4\" for partition 1 of 4 in chromosome 8\n    \"\"\"\n    chrom, suffix = chrom_w_suffix.split('-')\n    assert chrom in list(map(str, range(1,23)))+['X','Y'], \"chrom must be in  {1-22, X, Y}\"\n    part_idx, total_parts = map(int, suffix.split('of'))\n    assert (part_idx>=1) & (part_idx<=total_parts)\n    \n    total_vcfs = len(hl.hadoop_ls(get_gnomad_vcf_path(chrom=chrom, blocks=\"*\")))\n    \n    part_size = ceil(total_vcfs/total_parts)\n    \n    start_idx = (part_idx-1)*part_size\n    stop_idx = min((part_idx)*part_size-1, total_vcfs-1)\n    \n    return get_gnomad_vcf_path(chrom, blocks=range(start_idx, stop_idx+1))\n    \n    \n\ndef import_single_chrom_vcf(chrom, blocks = '*'):\n    if 'of' in str(chrom):\n        # Get chunk of chromosome\n        vcf_path = get_partitioned_chrom(chrom_w_suffix=chrom)\n    else:\n        vcf_path = get_gnomad_vcf_path(chrom=chrom, blocks=blocks)\n    \n    return hl.import_vcf(\n        vcf_path, \n        force_bgz=True,\n        reference_genome='GRCh38'\n    )\n\n\ndef get_mad_threshold_tsv_fname(n_mads, classification):\n    return f'ukb_wes_450k.mad_threshold.nmad_{n_mads}.popclass_{classification}.tsv.gz'\n\n\ndef get_pass_mad_threshold_expr(mt, n_mads='4', classification='strict'):\n    mad_fname = get_mad_threshold_tsv_fname(n_mads=n_mads, classification=classification)\n    mad_path = f'file:///mnt/project/data/03_mad_threshold/{mad_fname}'\n#     mad_path = f'file:///opt/notebooks/{mad_fname}'\n    print(mad_path)\n    mad_ht = hl.import_table(\n        mad_path, \n        types={\n            's': hl.tstr, \n            'pass': hl.tbool\n        },\n        key='s',\n        force=True\n    )\n    \n    return mad_ht[mt.s]['pass']\n\ndef get_fail_interval_qc_expr(mt):\n    return mt.info.fail_interval_qc\n\ndef get_lcr_expr(mt):\n    return mt.info.lcr\n\ndef get_segdup_expr(mt):\n    return mt.info.segdup\n\ndef get_filter_contains_rf_expr(mt):\n    return mt.filters.contains('RF')\n\ndef get_inbreeding_coeff(mt):\n    return mt.info.InbreedingCoeff[0]\n\ndef site_filter(mt):\n    # Set genotype to missing if:\n    # - DP < 10\n    # - GQ < 20\n    # - If heterozygous: Alt allele balance <= 0.2\n    \n    SITE_DP_MIN = 10\n    SITE_GQ_MIN = 20\n\n    pass_dp = mt.DP>=SITE_DP_MIN\n    pass_gq = mt.GQ>=SITE_GQ_MIN\n\n    pass_ab_het = mt.GT.is_het() & (mt.AD[1]/mt.DP>0.2)\n    pass_ab = ~mt.GT.is_het() | pass_ab_het\n    mt = mt.filter_entries(pass_dp & pass_gq & pass_ab)\n\n    return mt\n\n\ndef final_variant_filter(mt):\n    # Remove if:\n    # - FILTER row field contains \"RF\" (random forest true positive probability < {threshold})\n    # - Excess heterozygotes (inbreeding coefficient < -0.3)\n    # - Fails gnomAD interval QC\n    # - In low-complexity region\n    # - segdup is true (segment duplication region?)\n    # - No sample has a high quality genotype\n    \n    MIN_INBREEDING_COEFF = -0.3\n    fails_inbreeding_coeff = get_inbreeding_coeff(mt) < MIN_INBREEDING_COEFF\n    \n    # Fail if all genotypes are missing\n    fails_any_hq_genotypes = hl.agg.all(hl.is_missing(mt.GT))\n    \n    return mt.filter_rows(\n        get_filter_contains_rf_expr(mt)\n        | fails_inbreeding_coeff\n        | get_fail_interval_qc_expr(mt)\n        | get_lcr_expr(mt)\n        | get_segdup_expr(mt)\n        | fails_any_hq_genotypes,\n        keep=False\n    )\n\ndef export_table(ht, fname, out_folder):\n    ht.naive_coalesce(1).export(f'file:///opt/notebooks/{fname}')\n\n    dxpy.upload_local_file(\n        filename=f'/opt/notebooks/{fname}',\n        name=fname,\n        folder=out_folder,\n        parents=True\n    )\n    \ndef export_file(path, out_folder):\n    dxpy.upload_local_file(\n        filename=path,\n        name=path.split('/')[-1],\n        folder=out_folder,\n        parents=True\n    )\n\ndef final_filter(mt):\n    pass_mad_threshold_expr = get_pass_mad_threshold_expr(mt, n_mads='4', classification='strict')\n    mt = mt.filter_cols(pass_mad_threshold_expr)\n\n    mt = site_filter(mt)\n\n    # NOTE: Final variant filter MUST come after site filter in order to remove variants where no individuals have high quality genotypes\n    mt = final_variant_filter(mt)\n    \n    return mt\n\ndef get_final_filter_mt_path(chrom):\n    return f'{database_dir}/04_final_filter_write_to_mt/ukb_wes_450k.qced.chr{chrom}.mt'\n\ndef get_final_filter_count_tsv_fname(chrom):\n    return f'variant_sample_count.final_filter.c{chrom}.tsv'\n\n\ndef export_count_as_tsv(mt, chrom, fname, out_folder):\n    row_ct, col_ct = mt.count()\n    \n    df = pd.DataFrame(data={\n        'row_count': [row_ct], \n        'col_count': [col_ct]\n    })\n    ht = hl.Table.from_pandas(df)\n\n    export_table(\n        ht=ht, \n        fname=fname, \n        out_folder=out_folder\n    )", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "%%time\n\nchrom = chrom\n\nraw = import_single_chrom_vcf(chrom)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### S0.1. Write sample and variant files", "metadata": {}}, {"cell_type": "code", "source": "#Write file of samples to keep\npass_mad_threshold_expr = get_pass_mad_threshold_expr(mt, n_mads='4', classification='strict')\nmt = mt.filter_cols(pass_mad_threshold_expr)\nmt.cols()\n", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "\nmt = site_filter(mt)\n\n# NOTE: Final variant filter MUST come after site filter in order to remove variants where no individuals have high quality genotypes\nmt = final_variant_filter(mt)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## S1. Filter", "metadata": {}}, {"cell_type": "code", "source": "%%time\n\nmt = final_filter(mt=raw)", "metadata": {"trusted": true}, "execution_count": 7, "outputs": [{"name": "stdout", "text": "file:///mnt/project/data/03_mad_threshold/ukb_wes_450k.mad_threshold.nmad_4.popclass_strict.tsv.gz\nCPU times: user 113 ms, sys: 6.73 ms, total: 119 ms\nWall time: 2.29 s\n", "output_type": "stream"}, {"name": "stderr", "text": "2022-09-27 10:51:54 Hail: INFO: Loading 30 fields. Counts by type:\n  str: 29\n  bool: 1\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "## S2. Write to MatrixTable", "metadata": {}}, {"cell_type": "code", "source": "%%time\n\nmt = mt.rename({'info':'gnomad_info'})\nmt.write(get_final_filter_mt_path(chrom), overwrite=True)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "%%time\n\n# TEMPORARY\n# Export to PLINK format\n\nLOCAL_WD = '/opt/notebooks'\n\nlocal_path = f'{LOCAL_WD}/test_chr{chrom}'\n\nhl.export_plink(\n    dataset=mt,\n    output = f'file://{local_path}'\n)", "metadata": {"trusted": true}, "execution_count": null, "outputs": [{"name": "stderr", "text": "2022-09-27 10:55:29 Hail: INFO: Coerced sorted dataset\n2022-09-27 10:58:43 Hail: INFO: Coerced sorted dataset\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "for suffix in ['bed','bim','fam']:\n    export_file(\n        path=f'{LOCAL_WD}/chr{chrom}.{suffix}', \n        out_folder='/data/07_export_to_plink'\n    )", "metadata": {"trusted": true}, "execution_count": 8, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-8-084fdaecbe14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     export_file(\n\u001b[1;32m      3\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'/opt/notebooks/chr{chrom}.{suffix}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mout_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/07_export_to_plink'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     )\n", "\u001b[0;32m<ipython-input-3-cc0ee7946132>\u001b[0m in \u001b[0;36mexport_file\u001b[0;34m(path, out_folder)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dxpy/bindings/dxfile_functions.py\u001b[0m in \u001b[0;36mupload_local_file\u001b[0;34m(filename, file, media_type, keep_open, wait_on_close, use_existing_dxfile, show_progress, write_buffer_size, multithread, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     '''\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/opt/notebooks/chr21.bed'"], "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: '/opt/notebooks/chr21.bed'", "output_type": "error"}]}, {"cell_type": "markdown", "source": "## S3. Save row and column counts", "metadata": {}}, {"cell_type": "code", "source": "# %%time\n\n# for chrom in range(1,23):\n#     try:\n#         mt = hl.read_matrix_table(get_final_filter_mt_path(chrom))\n\n#         fname = get_final_filter_count_tsv_fname(chrom)\n#         out_folder = '/data/04_final_filter_write_to_mt'\n\n#         export_count_as_tsv(\n#             mt=mt, \n#             chrom=chrom, \n#             fname=fname,\n#             out_folder=out_folder\n#         )\n#     except:\n#         print(fai)", "metadata": {"trusted": true}, "execution_count": 8, "outputs": [{"name": "stderr", "text": "2022-08-23 16:09:35 Hail: INFO: merging 1 files totalling 34...\n2022-08-23 16:09:37 Hail: INFO: while writing:\n    file:///opt/notebooks/variant_sample_count.final_filter.c18.tsv\n  merge time: 1.075s\n", "output_type": "stream"}, {"name": "stdout", "text": "CPU times: user 149 ms, sys: 6.18 ms, total: 156 ms\nWall time: 4min 5s\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "## S4. Check sample counts", "metadata": {}}, {"cell_type": "code", "source": "for chrom in range(1,23):\n    try:\n        mt = hl.read_matrix_table(get_final_filter_mt_path(chrom))\n        print(f'chr{chrom} samples: {mt.count_cols()}')\n    except: \n        print(f'failed chrom{chrom}')", "metadata": {"trusted": true}, "execution_count": 8, "outputs": [{"name": "stdout", "text": "failed chrom1\nchr2 samples: 418156\nchr3 samples: 418156\nchr4 samples: 418156\nchr5 samples: 418156\nchr6 samples: 418156\nchr7 samples: 418156\nfailed chrom8\nchr9 samples: 418156\nchr10 samples: 418156\nchr11 samples: 418156\nchr12 samples: 418156\nchr13 samples: 418156\nchr14 samples: 418156\nchr15 samples: 418156\nfailed chrom16\nchr17 samples: 418156\nchr18 samples: 418156\nchr19 samples: 418156\nchr20 samples: 418156\nchr21 samples: 418156\nchr22 samples: 418156\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mt.cols().", "metadata": {"trusted": true}, "execution_count": 5, "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "418156"}, "metadata": {}}]}, {"cell_type": "code", "source": "final_filter_vcf_path = 'file:///mnt/project/data/04_final_filter/ukb_wes_450k.qced.c21_b0.vcf.gz'\n\nvcf =  hl.import_vcf(\n    final_filter_vcf_path, \n    force_bgz=True,\n    reference_genome='GRCh38'\n)", "metadata": {"trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "code", "source": "vcf.count_cols()", "metadata": {"trusted": true}, "execution_count": 7, "outputs": [{"execution_count": 7, "output_type": "execute_result", "data": {"text/plain": "418148"}, "metadata": {}}]}, {"cell_type": "code", "source": "pass_samples_path = 'file:///mnt/project/data/04_final_filter/ukb_wes_450k.pass_samples.tsv.gz'\n\nht = hl.import_table(\n    pass_samples_path,\n    force=True\n)", "metadata": {"trusted": true}, "execution_count": 9, "outputs": [{"name": "stderr", "text": "2022-09-28 10:00:46 Hail: INFO: Reading table without type imputation\n  Loading field 's' as type str (not specified)\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}