{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "chrom = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "\n",
    "WD='/opt/notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\n",
      "SparkUI available at http://ip-10-60-75-185.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.78-b17627756568\n",
      "LOGGING: writing to /opt/notebooks/hail-20220826-1222-0.2.78-b17627756568.log\n"
     ]
    }
   ],
   "source": [
    "my_database = dxpy.find_one_data_object(\n",
    "    name=\"my_database\", \n",
    "    project=dxpy.find_one_project()[\"id\"]\n",
    ")[\"id\"]\n",
    "database_dir = f'dnax://{my_database}'\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "hl.init(sc=sc, tmp_dir=f'{database_dir}/tmp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S0. Define functions, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnomad_vcf_path(chrom, blocks):\n",
    "    vcf_dir = 'file:///mnt/project/Bulk/Exome sequences_Alternative exome processing/Exome variant call files (gnomAD) (VCFs)'\n",
    "    if blocks != '*':\n",
    "        blocks = '{'+','.join(map(str, blocks))+'}'\n",
    "        \n",
    "    return f'{vcf_dir}/ukb24068_c{chrom}_b{blocks}_v1.vcf.gz'\n",
    "\n",
    "\n",
    "def get_partitioned_chrom(chrom_w_suffix):\n",
    "    \"\"\"\n",
    "    chrom_w_suffix should be of the form \"{chr}-?of?\", e.g. \"8-1of4\" for partition 1 of 4 in chromosome 8\n",
    "    \"\"\"\n",
    "    chrom, suffix = chrom_w_suffix.split('-')\n",
    "    assert chrom in list(map(str, range(1,23)))+['X','Y'], \"chrom must be in  {1-22, X, Y}\"\n",
    "    part_idx, total_parts = map(int, suffix.split('of'))\n",
    "    assert (part_idx>=1) & (part_idx<=total_parts)\n",
    "    \n",
    "    total_vcfs = len(hl.hadoop_ls(get_gnomad_vcf_path(chrom=chrom, blocks=\"*\")))\n",
    "    \n",
    "    part_size = ceil(total_vcfs/total_parts)\n",
    "    \n",
    "    start_idx = (part_idx-1)*part_size\n",
    "    stop_idx = min((part_idx)*part_size-1, total_vcfs-1)\n",
    "    \n",
    "    return get_gnomad_vcf_path(chrom, blocks=range(start_idx, stop_idx+1))\n",
    "    \n",
    "    \n",
    "\n",
    "def import_single_chrom_vcf(chrom, blocks = '*'):\n",
    "    if 'of' in str(chrom):\n",
    "        # Get chunk of chromosome\n",
    "        vcf_path = get_partitioned_chrom(chrom_w_suffix=chrom)\n",
    "    else:\n",
    "        vcf_path = get_gnomad_vcf_path(chrom=chrom, blocks=blocks)\n",
    "    \n",
    "    return hl.import_vcf(\n",
    "        vcf_path, \n",
    "        force_bgz=True,\n",
    "        reference_genome='GRCh38'\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mad_threshold_tsv_fname(n_mads, classification):\n",
    "    return f'ukb_wes_450k.mad_threshold.nmad_{n_mads}.popclass_{classification}.tsv.gz'\n",
    "\n",
    "\n",
    "def get_pass_mad_threshold_expr(mt, n_mads='4', classification='strict'):\n",
    "    mad_fname = get_mad_threshold_tsv_fname(n_mads=n_mads, classification=classification)\n",
    "    mad_path = f'file:///mnt/project/data/03_mad_threshold/{mad_fname}'\n",
    "#     mad_path = f'file:///opt/notebooks/{mad_fname}'\n",
    "    print(mad_path)\n",
    "    mad_ht = hl.import_table(\n",
    "        mad_path, \n",
    "        types={\n",
    "            's': hl.tstr, \n",
    "            'pass': hl.tbool\n",
    "        },\n",
    "        key='s',\n",
    "        force=True\n",
    "    )\n",
    "    \n",
    "    return mad_ht[mt.s]['pass']\n",
    "\n",
    "def get_fail_interval_qc_expr(mt):\n",
    "    return mt.info.fail_interval_qc\n",
    "\n",
    "def get_lcr_expr(mt):\n",
    "    return mt.info.lcr\n",
    "\n",
    "def get_segdup_expr(mt):\n",
    "    return mt.info.segdup\n",
    "\n",
    "def get_filter_contains_rf_expr(mt):\n",
    "    return mt.filters.contains('RF')\n",
    "\n",
    "def get_inbreeding_coeff(mt):\n",
    "    return mt.info.InbreedingCoeff[0]\n",
    "\n",
    "def site_filter(mt):\n",
    "    # Set genotype to missing if:\n",
    "    # - DP < 10\n",
    "    # - GQ < 20\n",
    "    # - If heterozygous: Alt allele balance <= 0.2\n",
    "    \n",
    "    SITE_DP_MIN = 10\n",
    "    SITE_GQ_MIN = 20\n",
    "\n",
    "    pass_dp = mt.DP>=SITE_DP_MIN\n",
    "    pass_gq = mt.GQ>=SITE_GQ_MIN\n",
    "\n",
    "    pass_ab_het = mt.GT.is_het() & (mt.AD[1]/mt.DP>0.2)\n",
    "    pass_ab = ~mt.GT.is_het() | pass_ab_het\n",
    "    mt = mt.filter_entries(pass_dp & pass_gq & pass_ab)\n",
    "\n",
    "    return mt\n",
    "\n",
    "\n",
    "def final_variant_filter(mt):\n",
    "    # Remove if:\n",
    "    # - FILTER row field contains \"RF\" (random forest true positive probability < {threshold})\n",
    "    # - Excess heterozygotes (inbreeding coefficient < -0.3)\n",
    "    # - Fails gnomAD interval QC\n",
    "    # - In low-complexity region\n",
    "    # - segdup is true (segment duplication region?)\n",
    "    # - No sample has a high quality genotype\n",
    "    \n",
    "    MIN_INBREEDING_COEFF = -0.3\n",
    "    fails_inbreeding_coeff = get_inbreeding_coeff(mt) < MIN_INBREEDING_COEFF\n",
    "    \n",
    "    # Fail if all genotypes are missing\n",
    "    fails_any_hq_genotypes = hl.agg.all(hl.is_missing(mt.GT))\n",
    "    \n",
    "    return mt.filter_rows(\n",
    "        get_filter_contains_rf_expr(mt)\n",
    "        | fails_inbreeding_coeff\n",
    "        | get_fail_interval_qc_expr(mt)\n",
    "        | get_lcr_expr(mt)\n",
    "        | get_segdup_expr(mt)\n",
    "        | fails_any_hq_genotypes,\n",
    "        keep=False\n",
    "    )\n",
    "\n",
    "def export_table(ht, fname, out_folder):\n",
    "    ht.naive_coalesce(1).export(f'file:///opt/notebooks/{fname}')\n",
    "\n",
    "    dxpy.upload_local_file(\n",
    "        filename=f'/opt/notebooks/{fname}',\n",
    "        name=fname,\n",
    "        folder=out_folder,\n",
    "        parents=True\n",
    "    )\n",
    "\n",
    "def final_filter(mt):\n",
    "    pass_mad_threshold_expr = get_pass_mad_threshold_expr(mt, n_mads='4', classification='strict')\n",
    "    mt = mt.filter_cols(pass_mad_threshold_expr)\n",
    "\n",
    "    mt = site_filter(mt)\n",
    "\n",
    "    # NOTE: Final variant filter MUST come after site filter in order to remove variants where no individuals have high quality genotypes\n",
    "    mt = final_variant_filter(mt)\n",
    "    \n",
    "    return mt\n",
    "\n",
    "def get_final_filter_mt_path(chrom):\n",
    "    return f'{database_dir}/04_final_filter_write_to_mt/ukb_wes_450k.qced.chr{chrom}.mt'\n",
    "\n",
    "def get_final_filter_count_tsv_fname(chrom):\n",
    "    return f'variant_sample_count.final_filter.c{chrom}.tsv'\n",
    "\n",
    "\n",
    "def export_count_as_tsv(mt, chrom, fname, out_folder):\n",
    "    row_ct, col_ct = mt.count()\n",
    "    \n",
    "    df = pd.DataFrame(data={\n",
    "        'row_count': [row_ct], \n",
    "        'col_count': [col_ct]\n",
    "    })\n",
    "    ht = hl.Table.from_pandas(df)\n",
    "\n",
    "    export_table(\n",
    "        ht=ht, \n",
    "        fname=fname, \n",
    "        out_folder=out_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.8 ms, sys: 1.71 ms, total: 56.5 ms\n",
      "Wall time: 54.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chrom = chrom\n",
    "\n",
    "raw = import_single_chrom_vcf(chrom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mt = final_filter(mt=raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2. Write to MatrixTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mt = mt.rename({'info':'gnomad_info'})\n",
    "\n",
    "# TEMPORARY?\n",
    "# Try selecting GT as the only entry field to save space and runtime\n",
    "mt = mt.select_entries('GT')\n",
    "\n",
    "# TEMPORARY\n",
    "chrom = f'{chrom}.GT-only'\n",
    "\n",
    "mt.write(get_final_filter_mt_path(chrom), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3. Save row and column counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mt = hl.read_matrix_table(get_final_filter_mt_path(chrom))\n",
    "\n",
    "    fname = get_final_filter_count_tsv_fname(chrom)\n",
    "    out_folder = '/data/04_final_filter_write_to_mt'\n",
    "\n",
    "    export_count_as_tsv(\n",
    "        mt=mt, \n",
    "        chrom=chrom, \n",
    "        fname=fname,\n",
    "        out_folder=out_folder\n",
    "    )\n",
    "except:\n",
    "    print(f'failed chr{chrom}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:09:35 Hail: INFO: merging 1 files totalling 34...\n",
      "2022-08-23 16:09:37 Hail: INFO: while writing:\n",
      "    file:///opt/notebooks/variant_sample_count.final_filter.c18.tsv\n",
      "  merge time: 1.075s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 6.18 ms, total: 156 ms\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# for chrom in range(1,23):\n",
    "#     try:\n",
    "#         mt = hl.read_matrix_table(get_final_filter_mt_path(chrom))\n",
    "\n",
    "#         fname = get_final_filter_count_tsv_fname(chrom)\n",
    "#         out_folder = '/data/04_final_filter_write_to_mt'\n",
    "\n",
    "#         export_count_as_tsv(\n",
    "#             mt=mt, \n",
    "#             chrom=chrom, \n",
    "#             fname=fname,\n",
    "#             out_folder=out_folder\n",
    "#         )\n",
    "#     except:\n",
    "#         print(fai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
